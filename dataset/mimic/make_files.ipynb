{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form the spider json \n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "tables = pd.read_json(\"/blue/daisyw/somasundaramv/DAIL-SQL/dataset/mimic/tables.json\")\n",
    "ops = {0:'=', 1:'>', 2:'<', 3:'>=', 4:'<='}\n",
    "\n",
    "def get_schema_fk(cur):\n",
    "    # foreign keys\n",
    "    fk = []\n",
    "    if len(cur['table']) == 1:\n",
    "        fk = None\n",
    "    else:\n",
    "        for i in range(0, len(cur['table'])):\n",
    "            for j in range(i+1, len(cur['table'])):\n",
    "                fk.append((tables[\"table_names\"][0][i]+\".HADM_ID\", tables[\"table_names\"][0][j]+\".HADM_ID\"))    \n",
    "    \n",
    "    # conditions\n",
    "    conditions = []\n",
    "    if len(cur['cond']) == 0:\n",
    "        conditions = None\n",
    "    else:\n",
    "        offset = {0:0, 1:23, 2:28, 3:33, 4:41}\n",
    "        for i in range(0, len(cur['cond'])):\n",
    "            table = tables[\"table_names\"][0][cur['cond'][i][0]]\n",
    "            column_name = tables[\"column_names\"][0][cur['cond'][i][1] + offset[cur['cond'][i][0]]][1]\n",
    "            cond = ops[cur['cond'][i][2]]\n",
    "            value = cur['cond'][i][3]\n",
    "            conditions.append(table + \".\" + column_name + \" \" + cond + \" \" + str(value))\n",
    "    return fk, conditions\n",
    "\n",
    "def convert_to_spider(entry: dict):\n",
    "    out = {}\n",
    "    out['db_id'] = \"mimic_iv\"\n",
    "    out['query'] = entry['sql']\n",
    "    out['question'] = entry['question_refine']\n",
    "    out['question_toks'] = entry['question_refine_tok']\n",
    "    out[\"query_toks\"] = entry[\"sql_tok\"]\n",
    "    fk, conditions = get_schema_fk(entry['format'])\n",
    "    out[\"fk\"] = str(fk)\n",
    "    out[\"cond\"] = str(conditions)\n",
    "    return out\n",
    "\n",
    "def convert(file: str):\n",
    "    data = [\n",
    "        # Your input data here\n",
    "    ]\n",
    "    \n",
    "    sql = [\n",
    "        # sql data here\n",
    "    ]\n",
    "\n",
    "    with open(file, 'r') as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            data.append(json.loads(line))\n",
    "            line = f.readline()\n",
    "            \n",
    "    out = []\n",
    "    for entry in data:\n",
    "        cur = convert_to_spider(entry)\n",
    "        sql.append(cur['query'])\n",
    "        out.append(cur)\n",
    "\n",
    "    json.dump(out, open(file.split(\".json\")[0]+\"formatted.json\", 'w'), indent=4)\n",
    "    \n",
    "    # write the sql to a sql file\n",
    "    with open(file.split(\".json\")[0]+\".sql\", 'w') as f:\n",
    "        for entry in sql:\n",
    "            f.write(entry + \"\\n\")\n",
    "\n",
    "convert(\"test.json\")\n",
    "convert(\"train.json\")\n",
    "convert(\"dev.json\")\n",
    "        \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
